---
title: "YARGODYNE Predictive Keyboard App"
author: "Alejandro Borges Sanchez"
date: "`r Sys.Date()`"
output: ioslides_presentation
---

```{r setup, include=FALSE}
library(tidyverse)
library(targets)
knitr::opts_chunk$set(echo = FALSE)
```

## The Algorithm

-   Kneser-Ney smoothed, top of the line high performance algorithm as implemented by [Keneth Heafield](https://kheafield.com/code/kenlm) and described in his [seminal paper](https://kheafield.com/papers/edinburgh/estimate_paper.pdf).

-   It allows us to estimate the language model through pruning and compute perplexity on large grids, thus yielding a small model yet with powerful estimation capability.

-   R interfaces for language model estimation and evaluation were built to automate the process in a reproducible r {targets} pipeline.

## Best model

-   The main constraint is model size, which is kept under 400mb.
-   Searching and finding the best model under this constraints was possible due to our algorithm implementation choice.

We searched through:

-   A grid of 1792 models:
    -   Of sample sizes from 10% to 90% of the language
    -   Both lower/upper cases
    -   Ngram orders ranging from 1 to 6
    -   Pruning ranging from 0 to 40

## Lowest perplexities by sample_size

```{r}
tar_read(consolidated_evaluations) %>%  
    rename(model_size=size) %>% 
    select(-model_file,-evaluated_on) %>% 
    select(1:5,model_size) %>% 
    filter(model_size<=fs::as_fs_bytes("400M")) %>% 
    group_by(case,order,prune,sample_size) %>% 
    filter(perplexity_including_oo_vs==min(perplexity_including_oo_vs)) %>% 
    group_by(sample_size) %>% 
    filter(perplexity_including_oo_vs==min(perplexity_including_oo_vs)) %>% 
    ungroup() %>% 
    arrange(perplexity_including_oo_vs) %>% 
  knitr::kable()
    
```

## The best model

It seems we can get close to a 400MB size model with the best perplexity using almost the whole corpus (90%) lower cased, building a 4-gram language model, pruning all singletons (prune=1) of all orders.

## The app

-   You can access the app here.

-   To use it, simply introduce your text and a 1 word completion should appear, representing the most probable ending to the phrase.

-   An animated graph interface shows the algorithm traversing the language model in real time.
